{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01f438f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: /home/hice1/wyiu31/scratch/venvs/llama32v/bin/python\n",
      "Torch: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "GPU: NVIDIA H100 80GB HBM3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hice1/wyiu31/scratch/venvs/llama32v/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, torch\n",
    "print(\"Python:\", sys.executable)\n",
    "print(\"Torch:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoProcessor, MllamaForConditionalGeneration,\n",
    "    BitsAndBytesConfig, TrainingArguments\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json, random\n",
    "import argparse\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoProcessor, MllamaForConditionalGeneration, BitsAndBytesConfig, TrainingArguments\n",
    "from peft import LoraConfig, get_peft_model\n",
    "from trl import SFTTrainer\n",
    "from PIL import Image\n",
    "import torch, os, re\n",
    "from dataclasses import dataclass\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2642aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:07<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model & processor loaded\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# Use your local model copy\n",
    "LOCAL_DIR = \"/home/hice1/wyiu31/scratch/models/llama32v\"\n",
    "os.environ[\"TRANSFORMERS_OFFLINE\"] = \"1\"\n",
    "\n",
    "# Safer default on shared GPUs (auto offload if VRAM is tight)\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    LOCAL_DIR, device_map=\"auto\", dtype=torch.float16, local_files_only=True\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(LOCAL_DIR, local_files_only=True)\n",
    "print(\"Model & processor loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f052107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n",
      "Read rows             : 11,608\n",
      "Considered total      : 11,608\n",
      "Wrote JSONL entries   : 6,273\n",
      "Skipped (no date)     : 0\n",
      "Skipped (no image hit): 5,335\n",
      "\n",
      "Examples with no image match (up to 10):\n",
      "  - loc=SM_4  date=02-11-2022  stem=IMG_0111  dir=/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/output/SM_4/02-11-2022\n",
      "  - loc=SM_4  date=02-11-2022  stem=IMG_0112  dir=/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/output/SM_4/02-11-2022\n",
      "  - loc=SM_4  date=02-11-2022  stem=IMG_0113  dir=/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/output/SM_4/02-11-2022\n",
      "  - loc=SM_4  date=02-11-2022  stem=IMG_0114  dir=/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/output/SM_4/02-11-2022\n",
      "  - loc=SM_4  date=02-11-2022  stem=IMG_0116  dir=/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/output/SM_4/02-11-2022\n",
      "  - loc=SM_4  date=02-11-2022  stem=IMG_0117  dir=/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/output/SM_4/02-11-2022\n",
      "  - loc=SM_4  date=02-11-2022  stem=IMG_0118  dir=/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/output/SM_4/02-11-2022\n",
      "  - loc=SM_4  date=02-11-2022  stem=IMG_0119  dir=/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/output/SM_4/02-11-2022\n",
      "  - loc=SM_4  date=02-11-2022  stem=IMG_0120  dir=/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/output/SM_4/02-11-2022\n",
      "  - loc=SM_5  date=02-11-2022  stem=IMG_0096  dir=/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/output/SM_5/02-11-2022\n",
      "\n",
      "Saved to: /home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/label_json/Observations_2022_with_images_v2.jsonl\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# make_jsonl_with_images.py\n",
    "from __future__ import annotations\n",
    "\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import List, Optional\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# ========= Paths (edit if needed) =========\n",
    "CSV_PATH = Path(\"/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/Observations_2022.csv\")\n",
    "IMG_BASE = Path(\"/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/output\")\n",
    "OUT_JSONL = Path(\"/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/label_json/Observations_2022_with_images_v2.jsonl\")\n",
    "\n",
    "# ========= Helpers =========\n",
    "\n",
    "EXT_RE = re.compile(r\"\\.(jpg|jpeg|png|bmp|gif|webp)$\", re.IGNORECASE)\n",
    "\n",
    "def parse_date_mmddyyyy(s: str) -> Optional[datetime]:\n",
    "    \"\"\"CSV has dates like 03/01/2022. Return datetime or None.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return None\n",
    "    s = s.strip()\n",
    "    if not s:\n",
    "        return None\n",
    "    for fmt in (\"%m/%d/%Y\", \"%m/%d/%y\"):\n",
    "        try:\n",
    "            return datetime.strptime(s, fmt)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return None\n",
    "\n",
    "def to_mm_dd_yyyy(d: datetime) -> str:\n",
    "    \"\"\"Folder format: MM-DD-YYYY.\"\"\"\n",
    "    return d.strftime(\"%m-%d-%Y\")\n",
    "\n",
    "def norm_common_name(s: str) -> str:\n",
    "    \"\"\"Keep as-is but trimmed; no 'Common Name:' prefix.\"\"\"\n",
    "    return str(s).strip()\n",
    "\n",
    "def norm_location(s: str) -> str:\n",
    "    \"\"\"Location folder is used as-is, but trim whitespace.\"\"\"\n",
    "    return str(s).strip()\n",
    "\n",
    "def norm_imagename(s: str) -> str:\n",
    "    \"\"\"\n",
    "    We search by 'starts with ImageName + \"__\"'. Keep the base name w/o extension.\n",
    "    e.g., 'IMG_0190'  -> match files like 'IMG_0190__20220402_184851__abc.JPG'\n",
    "    \"\"\"\n",
    "    s = str(s).strip()\n",
    "    s = re.sub(r\"\\.(jpg|jpeg|png|bmp|gif|webp)$\", \"\", s, flags=re.IGNORECASE)\n",
    "    return s\n",
    "\n",
    "def find_images_for(loc: str, date_folder: str, stem: str) -> List[str]:\n",
    "    \"\"\"Look under IMG_BASE/loc/date_folder for files starting with stem + '__'.\"\"\"\n",
    "    hits: List[str] = []\n",
    "    loc_dir = IMG_BASE / loc\n",
    "    date_dir = loc_dir / date_folder\n",
    "    if date_dir.exists() and date_dir.is_dir():\n",
    "        prefix = (stem + \"__\").upper()\n",
    "        for p in date_dir.iterdir():\n",
    "            if p.is_file() and EXT_RE.search(p.name) and p.name.upper().startswith(prefix):\n",
    "                hits.append(str(p))\n",
    "    return hits\n",
    "\n",
    "# ========= Load CSV =========\n",
    "\n",
    "CSV_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "OUT_JSONL.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df = pd.read_csv(CSV_PATH, sep=None, engine=\"python\", dtype=str)\n",
    "df.columns = df.columns.str.strip()\n",
    "# Drop unnamed auto-index cols\n",
    "df = df.loc[:, ~df.columns.str.match(r\"^Unnamed\", na=False)]\n",
    "\n",
    "# Ensure required columns exist\n",
    "required = {\"Location\", \"ImageName\", \"CommonName\"}\n",
    "missing = required - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"CSV is missing required columns: {sorted(missing)}\")\n",
    "\n",
    "# Pick date: prefer TrueDate, then CameraDate\n",
    "true_dates = df[\"TrueDate\"] if \"TrueDate\" in df.columns else None\n",
    "camera_dates = df[\"CameraDate\"] if \"CameraDate\" in df.columns else None\n",
    "\n",
    "picked_dates: list[Optional[datetime]] = []\n",
    "for i in range(len(df)):\n",
    "    d = None\n",
    "    if true_dates is not None:\n",
    "        d = parse_date_mmddyyyy(true_dates.iloc[i])\n",
    "    if d is None and camera_dates is not None:\n",
    "        d = parse_date_mmddyyyy(camera_dates.iloc[i])\n",
    "    picked_dates.append(d)\n",
    "\n",
    "df[\"_picked_date\"] = picked_dates\n",
    "df = df.dropna(subset=[\"Location\", \"ImageName\", \"CommonName\"], how=\"any\")\n",
    "\n",
    "# ========= Build JSONL =========\n",
    "\n",
    "total = 0\n",
    "wrote = 0\n",
    "no_date = 0\n",
    "no_img  = 0\n",
    "\n",
    "unmatched_samples = []  # for debugging printout\n",
    "\n",
    "with OUT_JSONL.open(\"w\", encoding=\"utf-8\") as fout:\n",
    "    for _, row in df.iterrows():\n",
    "        total += 1\n",
    "        loc = norm_location(row[\"Location\"])\n",
    "        stem = norm_imagename(row[\"ImageName\"])\n",
    "        label = norm_common_name(row[\"CommonName\"])\n",
    "        dt: Optional[datetime] = row[\"_picked_date\"]\n",
    "\n",
    "        if dt is None:\n",
    "            no_date += 1\n",
    "            # skip rows with no usable date (we don't know the folder)\n",
    "            continue\n",
    "\n",
    "        date_folder = to_mm_dd_yyyy(dt)\n",
    "        imgs = find_images_for(loc, date_folder, stem)\n",
    "\n",
    "        if not imgs:\n",
    "            no_img += 1\n",
    "            if len(unmatched_samples) < 10:\n",
    "                unmatched_samples.append({\n",
    "                    \"Location\": loc,\n",
    "                    \"date_folder\": date_folder,\n",
    "                    \"stem\": stem,\n",
    "                    \"hint_dir\": str(IMG_BASE / loc / date_folder)\n",
    "                })\n",
    "            # skip rows with no matching image\n",
    "            continue\n",
    "\n",
    "        rec = {\n",
    "            \"metadata\": {\n",
    "                \"location\": loc,\n",
    "                \"date\": date_folder,  # keep folder-ready format\n",
    "                \"stem\": stem,\n",
    "            },\n",
    "            \"images\": imgs,            # list[str]\n",
    "            \"output\": label,           # plain common name\n",
    "        }\n",
    "        fout.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
    "        wrote += 1\n",
    "\n",
    "print(f\"\\nDone.\")\n",
    "print(f\"Read rows             : {len(df):,}\")\n",
    "print(f\"Considered total      : {total:,}\")\n",
    "print(f\"Wrote JSONL entries   : {wrote:,}\")\n",
    "print(f\"Skipped (no date)     : {no_date:,}\")\n",
    "print(f\"Skipped (no image hit): {no_img:,}\")\n",
    "if unmatched_samples:\n",
    "    print(\"\\nExamples with no image match (up to 10):\")\n",
    "    for ex in unmatched_samples:\n",
    "        print(f\"  - loc={ex['Location']}  date={ex['date_folder']}  stem={ex['stem']}  dir={ex['hint_dir']}\")\n",
    "print(f\"\\nSaved to: {OUT_JSONL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a0dc351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines processed: 6273\n",
      "Unknown labels: 0/6273 = 0.0%\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "from pathlib import Path\n",
    "\n",
    "# Path to your observation file\n",
    "path = Path(\"/home/hice1/wyiu31/scratch/stonemt_cameratrap/Camera Trap Photos/label_json/Observations_2022_with_images_v2.jsonl\")\n",
    "\n",
    "total, unknown = 0, 0\n",
    "\n",
    "with path.open() as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        total += 1\n",
    "        try:\n",
    "            rec = json.loads(line)\n",
    "            # Combine possible text fields (adjust these keys if your schema differs)\n",
    "            text = json.dumps(rec)\n",
    "            if re.search(r\"\\bUnknown\\b\", text, re.IGNORECASE):\n",
    "                unknown += 1\n",
    "        except json.JSONDecodeError:\n",
    "            continue\n",
    "\n",
    "print(f\"Lines processed: {total}\")\n",
    "if total > 0:\n",
    "    print(f\"Unknown labels: {unknown}/{total} = {unknown/total:.1%}\")\n",
    "else:\n",
    "    print(\"No valid lines found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f080f11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama32v (scratch)",
   "language": "python",
   "name": "llama32v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
